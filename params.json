{"name":"Kraken","tagline":"Pubsub server for realtime apps","body":"### Overview\r\n\r\nKraken is a distributed pubsub server that is designed to power collaborative realtime apps like [Asana](http://www.asana.com).\r\n\r\nApplications use Kraken to transmit and receive messages through topics. These messages will typically contain just enough information\r\nto identify the set of data that was changed by the client just before the message was published. When other clients\r\nreceive these messages, they will figure out which data changed and reload it from the datastore so that they are eventually brought up to date.\r\n\r\nKraken is not a general purpose message bus like [RabbitMQ](http://www.rabbitmq.com/).\r\n\r\n### Building Kraken for the first time\r\n\r\nWe recommend running Kraken with [Erlang R15B03](http://www.erlang.org/download.html) and above, but it will likely work fine with older versions of Erlang as well.\r\n\r\nDownload the latest Kraken release (or clone the git project), and then use the following command from the root of the Kraken directory to build Kraken for the first time:\r\n\r\n    ./rebar get-deps compile\r\n\r\nYou can now run Kraken in the foreground like this:\r\n\r\n    bin/kraken run\r\n\r\nThis will start Kraken up with the default config. It will listen to new TCP connections on port 12355.\r\n\r\n### Running Kraken\r\n\r\nKraken comes with a little bash script that provides a handful of useful commands:\r\n\r\nRunning Kraken in the foreground, with a live erlang shell\r\n\r\n    bin/kraken run\r\n\r\nStarting and Stopping Kraken in the background\r\n\r\n    bin/kraken start\r\n    bin/kraken stop\r\n\r\nChecking if Kraken is currently running in the background\r\n\r\n    bin/kraken status\r\n\r\nChanging the Kraken log level while it is running\r\n\r\n    bin/kraken change_log_level [debug|info|warn|error]\r\n\r\nDumping information about every client queue\r\n\r\n    bin/kraken dump_queues\r\n\r\nDumping the list of topics for a particular client's queue\r\n\r\n    bin/kraken dump_queue_topics <pid from dump_queues>\r\n\r\nDumping all topics with a count of subscribers\r\n\r\n    bin/kraken dump_topics\r\n\r\n### Configuring Kraken\r\n\r\nBefore running Kraken in production, you will want to customize some of the config options. Kraken is built as a standard OTP application, so you can modify config options directly from the command line or by specifying a custom erlang config.\r\n\r\n#### Supported options\r\n\r\n* **pid_file**: If specified, then the system process id of the erlang node will be written to this file.\r\n* **listen_ip**: The IP address for the Kraken server to listen to new connections on.\r\n* **tcp_server_port**: The port for the Kraken server to listen to new connections on.\r\n* **num_router_shards**: The number of router shards to run. A good starting point is 2x the number of cores on the machine.\r\n* **router_min_fanout_to_warn**: Octopus will log warnings if a message ends up being distributed to this many or more subscribers.\r\n\r\n**Specifying options at the command line**\r\n\r\nYou can specify Kraken options at the command line when starting Kraken as follows:\r\n\r\n    bin/kraken run -kraken num_router_shards 8 -kraken router_min_fanout_to_warn 1000\r\n\r\nYou need to prefix each argument with \"-kraken\" to let erlang know that you are customizing the kraken application environment. Erlang lets you run multiple applications on a single node.\r\n\r\n**Specifying options in a config file**\r\n\r\nKraken options can also be specified in an erlang config file. Here is an example config file:\r\n\r\n    [{octopus, [\r\n       {pid_file, \"/var/run/kraken.pid\"},\r\n       {log_file, \"/var/log/kraken.log\"},\r\n       {max_tcp_clients, 30000},\r\n       {num_router_shards, 8}]}].\r\n\r\nIf you stored the config file in /etc/kraken.config, you could tell Erlang to use the config when you start it as follows:\r\n\r\n    bin/kraken start -config /etc/kraken\r\n\r\nNote that Erlang requires you to exclude the extension when you specify the config file.\r\n\r\n### Kraken clients\r\n\r\nKraken currently includes two official clients for Erlang and Node.js. The [Kraken protocol](https://github.com/Asana/Kraken/blob/master/src/kraken_memcached.erl) is based on the Memcached protocol, so it shouldn't take very long to create a client in the language of your choice. Please let us know if you create a new client!\r\n\r\nHere is an example of working with Kraken using the [Node.js client](https://github.com/Asana/kraken-node-client):\r\n\r\n    js> kraken1 = new Kraken(\"localhost\", 12355);\r\n    js> kranen2 = new Kraken(\"localhost\", 12355);\r\n    js> kraken1.subscribe([\"topicA\", \"topicB\"]);\r\n    js> kraken2.publish([\"topicA\"], \"hi there!\");\r\n    js> console.log(kraken1.receiveMessages());\r\n    js> kraken2.unsubscribe([\"topicA\"]);\r\n\r\nAs you see above, the Memcached based protocol requires clients to poll for new messages. Most good message bus proctocols (like AMQP) have some kind of polling in the form of a heart beat so that clients can detect dead connections sooner than later. In Kraken, the receive command is the way to receive new messages and the heartbeat at the same time. A decent machine should be able to handle thousands of clients polling once every couple of seconds without a problem. It probably wouldn't take very long to add a new protocol to Kraken that pushes messages to clients if you need it! Kraken was designed with the goal of supporting multiple protocols in the future.\r\n\r\n### How do I use Kraken to build realtime apps?\r\n\r\nKraken was designed to forward data invalidation messages between application servers. It's up to the application designer to figure out how to scope these messages to topics, and what they should contain. For example, a simple TODO list app may have topics corresponding to each of the lists that a user can see. This app would publish invalidation messages corresponding to the ids of tasks that have changed through the topics corresponding to the lists that the task is and was a member of. When other application servers receive these messages, they would reload the state of the tasks referenced in the invalidations messages to ensure they are still up to date.\r\n\r\n### How does Kraken scale?\r\n\r\nAs far as we know, very well. Kraken has been powering the Asana service since mid 2010, and has yet to crash or fail in any way. At Asana, we have 10s of thousands of clients connected to each Kraken node.\r\n\r\nThere are two ways of scaling Kraken beyond a single machine:\r\n\r\n1. You can shard the topic space so that each machine is responsible for a portion of the topics. This will typically decrease the total number of messages that a given node needs to process and reduce the amount of memory required to keep track of all the routing information.\r\n\r\n2. You can run Kraken nodes that proxy to other Kraken nodes. The proxy nodes will aggregate connections and routing information from their clients and forward on the minimal amount of information necessary to ensure they stay up to date. The proxy nodes then become a single client to the Kraken nodes that they connect to, substantially decreasing the total number of clients and messages that any single Kraken node needs to handle!\r\n\r\n### Authors and Contributors\r\n\r\nKraken was originally written by Kris Rasmussen (@krisr) at [Asana](http://www.asana.com/jobs). The Kraken mascot was designed by Stephanie Hornung.\r\n\r\n### Support or Contact\r\nHaving trouble with Kraken? Check out the documentation at https://github.com/Asana/Kraken/wiki or file an issue at https://github.com/Asana/Kraken/issues and weâ€™ll help you sort it out.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}